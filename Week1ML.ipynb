{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpJ9TPjTKJECiLF/jUO7Zo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RofiqAulia/Machine-Learning/blob/main/Week1ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts1E8HR4f1-7",
        "outputId": "83f303c7-ca40-43ab-de8f-7be4d53deb8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.16666666666666666, 0.3333333333333333, 0.6666666666666666, 1.0]\n",
            "\n",
            "\n",
            "Data Asli\n",
            "[[100.        0.10001]\n",
            " [ 50.        0.05   ]\n",
            " [ 30.        0.003  ]]\n",
            "Data Setelah dinormalisasi\n",
            "[[1.       1.      ]\n",
            " [0.285714 0.484486]\n",
            " [0.       0.      ]]\n",
            "\n",
            "\n",
            "Data Asli\n",
            "[[100.       0.0001]\n",
            " [ 50.       0.05  ]\n",
            " [ 30.       0.003 ]]\n",
            "Data Standarisasi\n",
            "[[ 1.358732 -0.76956 ]\n",
            " [-0.339683  1.412317]\n",
            " [-1.019049 -0.642757]]\n",
            "\n",
            "\n",
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi Ordinal Encoder\n",
            "[[1.]\n",
            " [0.]\n",
            " [3.]\n",
            " [2.]]\n",
            "\n",
            "\n",
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi Ordinal Encoder\n",
            "[[0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]]\n",
            "\n",
            "\n",
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi Ordinal Encoder\n",
            "[[1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]]\n",
            "\n",
            "\n",
            "Hasil TF-IDF\n",
            "  (0, 7)\t0.2808823162882302\n",
            "  (0, 6)\t0.5894630806320427\n",
            "  (0, 11)\t0.5894630806320427\n",
            "  (0, 5)\t0.47557510189256375\n",
            "  (1, 9)\t0.7297183669435993\n",
            "  (1, 2)\t0.5887321837696324\n",
            "  (1, 7)\t0.3477147117091919\n",
            "  (2, 1)\t0.5894630806320427\n",
            "  (2, 8)\t0.5894630806320427\n",
            "  (2, 7)\t0.2808823162882302\n",
            "  (2, 5)\t0.47557510189256375\n",
            "  (3, 0)\t0.5894630806320427\n",
            "  (3, 4)\t0.5894630806320427\n",
            "  (3, 2)\t0.47557510189256375\n",
            "  (3, 7)\t0.2808823162882302\n",
            "  (4, 10)\t0.6700917930430479\n",
            "  (4, 3)\t0.6700917930430479\n",
            "  (4, 7)\t0.3193023297639811\n",
            "hasil Token\n",
            "['ate' 'away' 'cat' 'end' 'finally' 'house' 'little' 'mouse' 'ran' 'saw'\n",
            " 'story' 'tiny']\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Implementasi Normalisasi\n",
        "def norm_data(data) :\n",
        "  '''\n",
        "  Fungsi ini digunakan untuk\n",
        "  Melakukan normaliasasi data.\n",
        "\n",
        "  Parameters::\n",
        "    data(list):data yang akan dinormaliasaikan\n",
        "  Retruns:\n",
        "    data (list) : data yang sudah dinormaliasikan\n",
        "  '''\n",
        "  data_max = max(data)\n",
        "  data_min = min(data)\n",
        "  data_len = len(data)\n",
        "\n",
        "  for i in range(0, data_len) :\n",
        "    data[i] = (data[i]- data_min) / (data_max - data_min)\n",
        "  return data\n",
        "\n",
        "# Contoh penggunaan\n",
        "data = [10, 11, 12, 14, 16]\n",
        "n_data = norm_data(data) # melakukan normalisasi\n",
        "print(n_data)\n",
        "print('\\n')\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "np.set_printoptions(precision=6) # bulatkan 4 angka koma\n",
        "np.set_printoptions(suppress=True) # hilangkan nilai e\n",
        "\n",
        "\n",
        "# Kita akan membentuk data\n",
        "# Hal ini dikarenakan, sedikitnya-leran hanya menerima input\n",
        "# Dalam bentuk n-dimensional array\n",
        "\n",
        "data = [\n",
        "    [100,0.10001],\n",
        "    [50,0.05],\n",
        "    [30,0.003]\n",
        "]\n",
        "\n",
        "#  Ubah ke bentuk array numpy n-dimensional array\n",
        "data = np.array(data)\n",
        "print(\"Data Asli\")\n",
        "print(data)\n",
        "\n",
        "# Mendefinikan objek MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "# Transformasikan data\n",
        "scaled = scaler.fit_transform(data)\n",
        "print(\"Data Setelah dinormalisasi\")\n",
        "print(scaled)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "# Implemenasi Standarisasi\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.set_printoptions(precision=6) # bulatkan 4 angka koma\n",
        "np.set_printoptions(suppress=True) # hilangkan nilai e\n",
        "\n",
        "# Kita akan membentuk data\n",
        "# Hal ini dikarenakan scikitnya-learn hanya menerima input\n",
        "# Dalam bentuk n-dimensional array\n",
        "\n",
        "data = [\n",
        "    [100,0.0001],\n",
        "    [50,0.05],\n",
        "    [30,0.003]\n",
        "]\n",
        "\n",
        "# Ubah ke bentuk numpy n-dimensional array\n",
        "data = np.array(data)\n",
        "print(\"Data Asli\")\n",
        "print(data)\n",
        "\n",
        "# Mendefinisikan objek MinMaxScaler\n",
        "scaler = StandardScaler()\n",
        "# Transformasikan data\n",
        "scaled = scaler.fit_transform(data)\n",
        "print(\"Data Standarisasi\")\n",
        "print(scaled)\n",
        "print('\\n')\n",
        "\n",
        "# 3. Implementasi Ordinal Encoding\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Inisialisasi obyek Encoder\n",
        "oe = OrdinalEncoder()\n",
        "\n",
        "# Definisikan data\n",
        "# Dalam bentuk 2D\n",
        "\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri jakarta'],\n",
        "    ['Politeknik Negeri Semarang']\n",
        "]\n",
        "\n",
        "# Transformasikan data\n",
        "transform_eo = oe.fit_transform(data)\n",
        "\n",
        "print(\"Data Asli\")\n",
        "print(data)\n",
        "print(\"Data Transformasi Ordinal Encoder\")\n",
        "print(transform_eo)\n",
        "print('\\n')\n",
        "\n",
        "# 4. Implementasi One-Hot Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Inisialisasi obyek Encoder\n",
        "ohe = OneHotEncoder()\n",
        "\n",
        "# Definisikan data\n",
        "# Dalam bentuk 2D\n",
        "\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri jakarta'],\n",
        "    ['Politeknik Negeri Semarang']\n",
        "]\n",
        "\n",
        "# Transformasikan data\n",
        "transform_eho = ohe.fit_transform(data)\n",
        "\n",
        "print(\"Data Asli\")\n",
        "print(data)\n",
        "print(\"Data Transformasi Ordinal Encoder\")\n",
        "print(transform_eho.toarray())\n",
        "print('\\n')\n",
        "\n",
        "# 5. Implementasi Dummy Variable Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Inisialisasi obyek Encoder\n",
        "de = OneHotEncoder(drop='first')\n",
        "\n",
        "# Definisikan data\n",
        "# Dalam bentuk 2D\n",
        "\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri jakarta'],\n",
        "    ['Politeknik Negeri Semarang']\n",
        "]\n",
        "\n",
        "# Transformasikan data\n",
        "transform_de = de.fit_transform(data)\n",
        "\n",
        "print(\"Data Asli\")\n",
        "print(data)\n",
        "print(\"Data Transformasi Ordinal Encoder\")\n",
        "print(transform_de.toarray())\n",
        "print('\\n')\n",
        "\n",
        "# 6. Studi Kasus Ekstrasi Fitur dari Data Teks\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "corpus = [\n",
        "    'the house had a tiny little mouse',\n",
        "    'the cat saw the mouse',\n",
        "    'the mouse ran away from the house',\n",
        "    'the cat finally ate the mouse',\n",
        "    'the end of the mouse story'\n",
        "]\n",
        "\n",
        "# Inisiasi obyek TfdfVectorizer\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Pembobotan TF-IDF\n",
        "resp = vect.fit_transform(corpus)\n",
        "\n",
        "# Cetak Hasil\n",
        "print(\"Hasil TF-IDF\")\n",
        "print(resp)\n",
        "\n",
        "# Cetak token stopword\n",
        "print(\"hasil Token\")\n",
        "print(vect.get_feature_names_out())\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-SSfPLFFp4c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "with open('corpus.txt', 'r') as file:\n",
        "    corpus = file.readlines()\n",
        "\n",
        "# Inisiasi obyek TfdfVectorizer\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Pembobotan TF-IDF\n",
        "resp = vect.fit_transform(corpus)\n",
        "\n",
        "# Cetak Hasil\n",
        "print(\"Hasil TF-IDF\")\n",
        "print(resp)\n",
        "\n",
        "# Cetak token stopword\n",
        "print(\"hasil Token\")\n",
        "print(vect.get_feature_names_out())\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3lfy6FypufB",
        "outputId": "4b132674-cf76-4452-eae5-855837581259"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil TF-IDF\n",
            "  (0, 7)\t0.2808823162882302\n",
            "  (0, 6)\t0.5894630806320427\n",
            "  (0, 11)\t0.5894630806320427\n",
            "  (0, 5)\t0.47557510189256375\n",
            "  (1, 9)\t0.7297183669435993\n",
            "  (1, 2)\t0.5887321837696324\n",
            "  (1, 7)\t0.3477147117091919\n",
            "  (2, 1)\t0.5894630806320427\n",
            "  (2, 8)\t0.5894630806320427\n",
            "  (2, 7)\t0.2808823162882302\n",
            "  (2, 5)\t0.47557510189256375\n",
            "  (3, 0)\t0.5894630806320427\n",
            "  (3, 4)\t0.5894630806320427\n",
            "  (3, 2)\t0.47557510189256375\n",
            "  (3, 7)\t0.2808823162882302\n",
            "  (4, 10)\t0.6700917930430479\n",
            "  (4, 3)\t0.6700917930430479\n",
            "  (4, 7)\t0.3193023297639811\n",
            "hasil Token\n",
            "['ate' 'away' 'cat' 'end' 'finally' 'house' 'little' 'mouse' 'ran' 'saw'\n",
            " 'story' 'tiny']\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}